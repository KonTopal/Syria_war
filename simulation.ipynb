{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6e37ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "from numba import njit\n",
    "import imageio.v2 as imageio\n",
    "import glob\n",
    "from scipy.sparse import lil_matrix\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47da3537",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bkg_img():\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    bg_img = mpimg.imread('images/map_apple.png')\n",
    "    ymin, xmin = [32.31, 34.44]\n",
    "    ymax, xmax = [37.30, 42.77]\n",
    "    plt.xlim(xmin, xmax)\n",
    "    plt.ylim(ymin, ymax)\n",
    "\n",
    "    plt.xlabel(\"Longitude\")\n",
    "    plt.ylabel(\"Latitude\")\n",
    "    plt.imshow(bg_img, extent=[xmin, xmax, ymin, ymax], aspect='auto')\n",
    "\n",
    "def bkg_blank():\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    ymin, xmin = [32.31, 34.44]\n",
    "    ymax, xmax = [37.30, 42.77]\n",
    "    plt.xlim(xmin, xmax)\n",
    "    plt.ylim(ymin, ymax)\n",
    "\n",
    "    plt.xlabel(\"Longitude\")\n",
    "    plt.ylabel(\"Latitude\")\n",
    "\n",
    " #make colormaps (register for magma_r, viridis_r)\n",
    "\n",
    "mname = 'viridis_r'\n",
    "ncolors = 256\n",
    "color_array = plt.get_cmap(mname)(range(ncolors))\n",
    "\n",
    "# change alpha values\n",
    "nlim = 30\n",
    "color_array[:nlim,-1] = np.linspace(0.0,1.0,nlim)\n",
    "\n",
    "# create a colormap object\n",
    "map_object = LinearSegmentedColormap.from_list(name=f'{mname}_alpha',colors=color_array)\n",
    "\n",
    "# register this new colormap with matplotlib\n",
    "plt.colormaps.register(cmap=map_object)\n",
    "\n",
    "# show some example data\n",
    "#f,ax = plt.subplots()\n",
    "#h = ax.imshow(np.random.rand(100,100),cmap=map_object)\n",
    "#plt.colorbar(mappable=h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006dda2f",
   "metadata": {},
   "source": [
    "#### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "225e5a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('data/populated_places/datafile_oilscore_minorities.dat', \"r\")\n",
    "next(f)\n",
    "content = f.readlines()\n",
    "f.close()\n",
    "    \n",
    "pop = []\n",
    "x_coord  = []\n",
    "y_coord  = []\n",
    "oilscore = []\n",
    "ethn_groups = []\n",
    "\n",
    "for line in content:\n",
    "    temp1 , temp2, temp3, temp4, *temp5 = line.strip().split()\n",
    "    pop += [float(temp1)]\n",
    "    x_coord  += [float(temp2)]\n",
    "    y_coord  += [float(temp3)]\n",
    "    oilscore += [float(temp4)]\n",
    "    ethn_groups += [temp5]\n",
    "\n",
    "x_coord = np.array(x_coord)\n",
    "y_coord = np.array(y_coord)\n",
    "pop = np.array(pop)\n",
    "oilscore = np.array(oilscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b599b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.    0.016 0.726 ... 1.78  2.237 0.258]\n",
      " [0.016 0.    0.71  ... 1.795 2.251 0.27 ]\n",
      " [0.726 0.71  0.    ... 2.484 2.931 0.893]\n",
      " ...\n",
      " [1.78  1.795 2.484 ... 0.    0.466 1.726]\n",
      " [2.237 2.251 2.931 ... 0.466 0.    2.191]\n",
      " [0.258 0.27  0.893 ... 1.726 2.191 0.   ]]\n"
     ]
    }
   ],
   "source": [
    "adj_geom = np.loadtxt('adj_geom.txt')\n",
    "\n",
    "print(adj_geom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8fa1c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "thr = 0.1\n",
    "adj_lim = adj_geom.copy()\n",
    "adj_lim[adj_lim > thr] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307a006e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'state': 0.0005792586450003632, 'sunni': 0.04534464452869004, 'kurds': 0.0016099047796869486}\n"
     ]
    }
   ],
   "source": [
    "f = open('data/initial/init_occupier.dat', \"r\")\n",
    "next(f)\n",
    "content = f.readlines()\n",
    "f.close()\n",
    "\n",
    "init_occ = np.array([line.strip() for line in content])\n",
    "\n",
    "f = open('data/betweenness_centrality/bce_values.txt', \"r\")\n",
    "next(f)\n",
    "content = f.readlines()\n",
    "f.close()\n",
    "\n",
    "bce_vals = np.array([float(line.strip()) for line in content])\n",
    "\n",
    "f = open('data/closeness_centrality/closeness_values.txt', \"r\")\n",
    "next(f)\n",
    "content = f.readlines()\n",
    "f.close()\n",
    "\n",
    "closeness_vals = np.array([float(line.strip()) for line in content])\n",
    "\n",
    "f = open('data/eigenvector_centrality/eigenvector_values.txt', \"r\")\n",
    "next(f)\n",
    "content = f.readlines()\n",
    "f.close()\n",
    "\n",
    "eigenvector_vals = np.array([float(line.strip()) for line in content])\n",
    "\n",
    "fiedler_values = {}\n",
    "with open(\"data/fiedler/fiedler_values.txt\") as f:\n",
    "    next(f)  # skip header\n",
    "    for line in f:\n",
    "        group, val = line.strip().split(\",\")\n",
    "        fiedler_values[group] = float(val)\n",
    "\n",
    "print(fiedler_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0453261",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_geom = nx.from_numpy_array(adj_lim)\n",
    "comps=sorted(nx.connected_components(G_geom))\n",
    "largest_component = comps[0]\n",
    "G_main = G_geom.subgraph(largest_component)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99d66ab",
   "metadata": {},
   "source": [
    "important cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76c2ee45",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = {'Damascus' : [36.29 , 33.51],\n",
    "          'Aleppo'   : [37.10 , 36.12],\n",
    "          'Homs'     : [36.72 , 34.73],\n",
    "          'Ar Raqqah': [39.01 , 35.95],\n",
    "          'Idlib'    : [36.63 , 35.93],\n",
    "          'Dayr az Zawr' : [40.14 , 35.34],\n",
    "          'Latakia'  : [35.79 , 35.53],\n",
    "          'Tartous'  : [35.89 , 34.89]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8235f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1274\n",
      "3.542\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "damascus_index = 6176\n",
    "distances_from_damascus = adj_geom[damascus_index]\n",
    "new_arr = distances_from_damascus[distances_from_damascus != 0.0]\n",
    "#print(distances_from_damascus[1195])\n",
    "print(np.argmax(new_arr))\n",
    "print(distances_from_damascus[np.argmax(new_arr)])\n",
    "\n",
    "#closeness_vals_nonzero=closeness_vals[closeness_vals != 0.0]\n",
    "#print(np.argmax(closeness_vals))\n",
    "#print(closeness_vals[np.argmax(closeness_vals)])\n",
    "\n",
    "#print(closeness_vals[6177])\n",
    "\n",
    "dam_norm = (distances_from_damascus - distances_from_damascus.min()) / \\\n",
    "           (distances_from_damascus.max() - distances_from_damascus.min())\n",
    "\n",
    "print(dam_norm[1274])\n",
    "#print(dam_norm[np.argmin(dam_norm)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fad17b",
   "metadata": {},
   "source": [
    "#### Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "16f1791e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "\n",
    "eps_dist = 0.3 #0.3\n",
    "c_pop = 0.01 #0.01\n",
    "c_os = 4.21 #4.21\n",
    "c_di = 0.76 #0.76\n",
    "c_ethn = 3 #3\n",
    "c_bce = 80 #80\n",
    "c_dam=0.1 #0.2\n",
    "c_closeness= 30 #30/40\n",
    "c_fiedler=45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a721d6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First iteration algorithm\n",
    "def charges_calc(occ_state):\n",
    "\n",
    "    occ_state = np.asarray(occ_state)\n",
    "    n = np.zeros(len(occ_state), dtype=float)\n",
    "\n",
    "    for i in range(len(occ_state)):\n",
    "        match = occ_state[i] in ethn_groups[i]      # True if the occupier matches a dominant ethnic group\n",
    "        n[i] = 0.01*( pop[i] + 100 )*( 1 + 0.5*(float(match) - 0.5) )\n",
    "\n",
    "    return n\n",
    "\n",
    "def battle(I, J, prob, charg, occ_state):\n",
    "\n",
    "    nI = prob*charg[I]     # attacker strength\n",
    "    nJ = charg[J]          # defender strength\n",
    "    diff = abs(nI-nJ)\n",
    "\n",
    "    charg[I] -= nI         # attacker looses strength they mobilised\n",
    "\n",
    "    if nI<=nJ:   \n",
    "        charg[J] -= nI     # defender loses equal strength\n",
    "    else:\n",
    "        occ_state[J] = occ_state[I]\n",
    "        charg[J] = diff  \n",
    "\n",
    "    return charg, occ_state\n",
    "\n",
    "def check_structural_collapse(occ_state, charges, loss_threshold, decay_factor):\n",
    "  \n",
    "    assad_nodes = np.where(occ_state == \"state\")[0]\n",
    "    \n",
    "    total_centrality = np.sum(eigenvector_vals[assad_nodes] + bce_vals[assad_nodes] + closeness_vals[assad_nodes])\n",
    "    \n",
    "    lost_nodes = np.where(occ_state != \"state\")[0]\n",
    "    lost_centrality = np.sum(eigenvector_vals[lost_nodes] + bce_vals[lost_nodes] + closeness_vals[lost_nodes])\n",
    "    \n",
    "    # Se la perdita supera la soglia â†’ collasso\n",
    "    if lost_centrality / total_centrality > loss_threshold:\n",
    "        for node in assad_nodes:\n",
    "            # Penalizza piÃ¹ i nodi lontani da Damasco\n",
    "            penalty = decay_factor + 0.5 * distances_from_damascus[node]  # piÃ¹ lontano = piÃ¹ riduzione\n",
    "            charges[node] *= max(0.2, 1 - penalty)  # non scendere sotto 10%\n",
    "    \n",
    "    return charges\n",
    "\n",
    "def iteration(init_state):\n",
    "    final_state = init_state.copy()\n",
    "    charges = charges_calc(init_state)\n",
    "\n",
    "    half_pi = np.pi / 2\n",
    "\n",
    "    for i in range(len(init_state)):\n",
    "        neighbour_indices = np.nonzero(adj_lim[i])[0]\n",
    "\n",
    "        if neighbour_indices.size == 0:\n",
    "            continue\n",
    "\n",
    "        # Get valid target neighbours (different occupier)\n",
    "        mask_diff = init_state[neighbour_indices] != init_state[i]\n",
    "        targets = neighbour_indices[mask_diff]\n",
    "\n",
    "        if targets.size == 0:\n",
    "            continue\n",
    "\n",
    "        dam_distances = distances_from_damascus[targets]\n",
    "\n",
    "        # Vectorised probability calculation\n",
    "        p_pop = np.arctan(c_pop * pop[targets] + eps_dist) / half_pi\n",
    "        p_os = 1 - np.arctan(c_os * oilscore[targets]) / half_pi\n",
    "        p_dis = 1 -  np.arctan(c_di * adj_geom[i, targets]) / half_pi\n",
    "        p_bce = np.arctan(c_bce * bce_vals[targets]) / half_pi\n",
    "        p_closeness = np.arctan(c_closeness * closeness_vals[targets]) / half_pi\n",
    "        p_eigenvector = eigenvector_vals[targets]\n",
    "        p_damascus = 1 - np.arctan(c_dam*dam_distances) / half_pi\n",
    "\n",
    "        probs = p_pop * p_os * p_dis * p_damascus\n",
    "        \n",
    "        \n",
    "\n",
    "        # combine with logical ... AND ... OR ... \n",
    "        #p_os_dis = p_os + p_dis - p_os*p_dis                            \n",
    "        #probs = p_pop * p_os_dis \n",
    "\n",
    "        # combine with logical ... OR ... AND ... \n",
    "        #p_os_dis = p_os * p_dis                             \n",
    "        #probs = p_pop + p_os_dis - p_pop*p_os_dis\n",
    "\n",
    "        # combine with logical ... OR ... OR ... \n",
    "        #p_os_dis = p_os + p_dis - p_os*p_dis                            \n",
    "        #probs = p_pop + p_os_dis - p_pop*p_os_dis\n",
    "\n",
    "        # centrality measures\n",
    "        probs = probs + p_bce - probs*p_bce\n",
    "        probs= probs + p_closeness - probs*p_closeness\n",
    "        probs = probs + p_eigenvector - probs*p_eigenvector\n",
    "\n",
    "        # Ethnic match bonus\n",
    "        ethnic_match = np.array( [init_state[i] in ethn_groups[t] for t in targets] )\n",
    "        probs[ethnic_match] = 1 - (1 - probs[ethnic_match]) / c_ethn\n",
    "\n",
    "        invade_idx = np.argmax(probs)\n",
    "        J = targets[invade_idx]\n",
    "\n",
    "        charges, final_state = battle(i, J, probs[invade_idx], charges, final_state)\n",
    "    \n",
    "    #charges = check_structural_collapse(final_state, charges, loss_threshold=3, decay_factor=0.5)\n",
    "\n",
    "\n",
    "    return final_state\n",
    "\n",
    "def plot_state_frame(occ_state,I):\n",
    "\n",
    "    bkg_blank()\n",
    "\n",
    "    ind_state = np.where(occ_state == \"state\")[0]\n",
    "    ind_sunni = np.where(occ_state == \"sunni\")[0]\n",
    "    ind_kurds = np.where(occ_state == \"kurds\")[0]\n",
    "\n",
    "    x_state, y_state = [x_coord[ind_state],y_coord[ind_state]]\n",
    "    x_sunni, y_sunni = [x_coord[ind_sunni],y_coord[ind_sunni]]\n",
    "    x_kurds, y_kurds = [x_coord[ind_kurds],y_coord[ind_kurds]]\n",
    "\n",
    "    heatmap, xedges, yedges = np.histogram2d(x_state, y_state, bins=300)\n",
    "    plt.imshow( heatmap.T, origin='lower', cmap='ocean_r', \n",
    "        extent=[xedges[0], xedges[-1], yedges[0], yedges[-1]], alpha = 1\n",
    "    )\n",
    "\n",
    "    heatmap, xedges, yedges = np.histogram2d(x_sunni, y_sunni, bins=200)\n",
    "    plt.imshow( heatmap.T, origin='lower', cmap='viridis_r_alpha', \n",
    "        extent=[xedges[0], xedges[-1], yedges[0], yedges[-1]], alpha = 1\n",
    "    )\n",
    "\n",
    "    heatmap, xedges, yedges = np.histogram2d(x_kurds, y_kurds, bins=200)\n",
    "    plt.imshow( heatmap.T, origin='lower', cmap='magma_r_alpha', \n",
    "        extent=[xedges[0], xedges[-1], yedges[0], yedges[-1]], alpha = 1\n",
    "    )\n",
    "\n",
    "    plt.text(\n",
    "        0.03, 0.9, f\"{I+1}\",\n",
    "        transform=plt.gca().transAxes,\n",
    "        fontsize=14, color='white',\n",
    "        bbox=dict(facecolor='black', alpha=0.5, boxstyle='round,pad=0.3')\n",
    "    )\n",
    "\n",
    "    for city in cities:\n",
    "        plt.scatter(cities[city][0], cities[city][1], c='black', s=1, marker='+')\n",
    "\n",
    "    plt.savefig(f'images/frames/frame_{I+1}.png', bbox_inches = 'tight', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    return [len(x_state),len(x_sunni),len(x_kurds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d161dc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Markov-chain based algorithm\n",
    "max_fiedler= max(fiedler_values.values())\n",
    "rng = np.random.default_rng()\n",
    "\n",
    "\n",
    "def compute_fiedler_values(occ_state, groups=['state', 'sunni', 'kurds']):\n",
    "    fiedler_vals = {}\n",
    "\n",
    "    for group in groups:\n",
    "        group_nodes = np.where(occ_state == group)[0]\n",
    "\n",
    "        if len(group_nodes) == 0:\n",
    "            fiedler_vals[group] = 0.0\n",
    "            continue\n",
    "\n",
    "        G_group = G_geom.subgraph(group_nodes).copy()\n",
    "\n",
    "        L_group = nx.laplacian_matrix(G_group).todense()\n",
    "        eigenvalues_group = np.linalg.eigvalsh(L_group)\n",
    "\n",
    "        # Takes the second-smallest eigenvalue (Fiedler value) of the Laplacian. \n",
    "        # We apply a numerical threshold to filter out values that are effectively zero \n",
    "        # due to floating-point precision, ensuring that only genuinely positive eigenvalues \n",
    "        # are considered. If none remain, we assign 0.0.\n",
    "        valid_eig = eigenvalues_group[eigenvalues_group > 3.08e-13]\n",
    "        fiedler_val = np.min(valid_eig) if len(valid_eig) > 0 else 0.0\n",
    "        fiedler_vals[group] = fiedler_val\n",
    "\n",
    "    return fiedler_vals\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "multipliers_base = {'state':1.0, 'sunni':1.0,'kurds':1.0}\n",
    "def charges_calc(occ_state, apply_fiedler_init=True, fiedler_init=None):\n",
    "    occ_state = np.asarray(occ_state)\n",
    "    n = np.zeros(len(occ_state), dtype=float)\n",
    "\n",
    "    for i in range(len(occ_state)):\n",
    "        faction = occ_state[i]\n",
    "        match = faction in ethn_groups[i] #True if the occupier matches a dominant ethnic group\n",
    "\n",
    "        base = 0.01 * (pop[i] + 100) * (1 + 0.5 * (float(match) - 0.5)) \n",
    "\n",
    "        mul = multipliers_base.get(faction, 1.0) \n",
    "        \n",
    "        if apply_fiedler_init and fiedler_init is not None:\n",
    "            fval = fiedler_init.get(faction, 0.0)\n",
    "            fscale = (fval / max_fiedler)  # in [0.5,1]\n",
    "            mul *= fscale\n",
    "            \n",
    "            n[i] = base * mul\n",
    "\n",
    "        else:  \n",
    "            n[i] = base \n",
    "\n",
    "    return n\n",
    "\n",
    "def check_structural_collapse(occ_state, charges, loss_threshold, decay_factor):\n",
    "  \n",
    "    state_nodes = np.where(occ_state == \"state\")[0]\n",
    "    \n",
    "    total_centrality = np.sum(eigenvector_vals[state_nodes] + bce_vals[state_nodes] + closeness_vals[state_nodes])\n",
    "    \n",
    "    lost_nodes = np.where(occ_state != \"state\")[0]\n",
    "    lost_centrality = np.sum(eigenvector_vals[lost_nodes] + bce_vals[lost_nodes] + closeness_vals[lost_nodes])\n",
    "    \n",
    "    #If the loss exceeds the threshold â†’ collapse\n",
    "    if lost_centrality / total_centrality > loss_threshold:\n",
    "        for node in state_nodes:\n",
    "            #Penalizes more the nodes far from Damascus\n",
    "            penalty = decay_factor + 0.5 * distances_from_damascus[node]  \n",
    "            charges[node] *= max(0.2, 0.5 - penalty)  \n",
    "    \n",
    "    return charges\n",
    "\n",
    "\n",
    "\n",
    "def battle(I, J, prob, charg, occ_state, attacker_label):\n",
    "   # def_factor = dynamic_def_factor(occ_state, attacker_label)\n",
    "    nI = prob*charg[I]     # attacker strength\n",
    "    nJ = charg[J]  #* def_factor   # defender strength\n",
    "    diff = abs(nI-nJ)\n",
    "\n",
    "    charg[I] -= nI\n",
    "\n",
    "    if nI<=nJ:   \n",
    "        charg[J] -= nI     # defender loses equal strength\n",
    "    else:\n",
    "        occ_state[J] = occ_state[I]\n",
    "        charg[J] = diff  \n",
    "\n",
    "    return charg, occ_state\n",
    "\n",
    "\n",
    "def iteration(init_state, charges, iter):\n",
    "    final_state = init_state.copy()\n",
    "    half_pi = np.pi / 2\n",
    "\n",
    "    n = len(init_state)\n",
    "    T = lil_matrix((n, n), dtype=float)   \n",
    "    planned_attacks = []\n",
    "\n",
    "\n",
    "    for i in range(n):\n",
    "        neighbour_indices = np.nonzero(adj_lim[i])[0]\n",
    "        if neighbour_indices.size == 0:\n",
    "            T[i, i] = 1.0\n",
    "            continue\n",
    "\n",
    "        \n",
    "\n",
    "        # Get valid target neighbours (different occupier)\n",
    "        mask_diff = final_state[neighbour_indices] != final_state[i]\n",
    "        targets = neighbour_indices[mask_diff]\n",
    "        mask_diff = final_state[neighbour_indices] == final_state[i]\n",
    "        friends = neighbour_indices[mask_diff]\n",
    "        if targets.size == 0:\n",
    "            continue\n",
    "\n",
    "        dam_distances = distances_from_damascus[targets]\n",
    "\n",
    "        # Vectorised probability calculation\n",
    "        p_pop = np.arctan(c_pop * pop[targets] + eps_dist) / half_pi\n",
    "        p_os = 1 - np.arctan(c_os * oilscore[targets]) / half_pi\n",
    "        p_dis = 1 -  np.arctan(c_di * adj_geom[i, targets]) / half_pi\n",
    "        p_bce = np.arctan(c_bce * bce_vals[targets]) / half_pi\n",
    "        p_closeness = np.arctan(c_closeness * closeness_vals[targets]) / half_pi\n",
    "        p_eigenvector = eigenvector_vals[targets]\n",
    "        p_damascus = 1 - np.arctan(c_dam*dam_distances) / half_pi\n",
    "\n",
    "        # combine with logical ... AND ... AND ...\n",
    "        probs = p_pop * p_os * p_dis * p_damascus\n",
    "        \n",
    "        # combine with logical ... AND ... OR ... \n",
    "        #p_os_dis = p_os + p_dis - p_os*p_dis                            \n",
    "        #probs = p_pop * p_os_dis \n",
    "\n",
    "        # combine with logical ... OR ... AND ... \n",
    "        #p_os_dis = p_os * p_dis                             \n",
    "        #probs = p_pop + p_os_dis - p_pop*p_os_dis\n",
    "\n",
    "        # combine with logical ... OR ... OR ... \n",
    "        #p_os_dis = p_os + p_dis - p_os*p_dis                            \n",
    "        #probs = p_pop + p_os_dis - p_pop*p_os_dis\n",
    "\n",
    "        # betweeness centrality\n",
    "        probs = probs + p_bce - probs*p_bce\n",
    "        probs= probs + p_closeness - probs*p_closeness\n",
    "        probs = probs + p_eigenvector - probs*p_eigenvector\n",
    "\n",
    "        \n",
    "        # Ethnic match bonus\n",
    "        ethnic_match = np.array( [init_state[i] in ethn_groups[t] for t in targets] )\n",
    "        if ethnic_match.any():\n",
    "            probs[ethnic_match] = 1 - (1 - probs[ethnic_match]) / c_ethn\n",
    "        \n",
    "        \n",
    "        dist_neigh = adj_geom[i, friends]\n",
    "        w_move = np.exp(-c_dam * dist_neigh)\n",
    "        eig_neigh = eigenvector_vals[friends]\n",
    "        clo_neigh = closeness_vals[friends]   \n",
    "        bce_neigh = bce_vals[friends]\n",
    "        w_move *= (1.0 + 2 * eig_neigh) * (1.0 + 1 * clo_neigh) * (1.0 + 1 * bce_neigh)\n",
    "        \n",
    "\n",
    "        s = w_move.sum()\n",
    "        if s <= 0:\n",
    "            # fallback: self loop\n",
    "            T[i, i] = 1.0\n",
    "        else:\n",
    "            w_norm = w_move / s\n",
    "            T[i, friends] = w_norm  #assign row i\n",
    "        \n",
    "        #\n",
    "\n",
    "\n",
    "        p_attack = probs / probs.sum()\n",
    "        \n",
    "        #extract a stochastic target J and save the attack \n",
    "        J = rng.choice(targets, p=p_attack)\n",
    "        prob_on_J = probs[targets == J][0]\n",
    "        planned_attacks.append((i, int(J), float(prob_on_J)))\n",
    "\n",
    "    T_csr = T.tocsr()\n",
    "    moved = T_csr.T.dot(charges)    #T^T @ charges\n",
    "    charges = (1.0 - 0.2) * charges + 0.2 * moved\n",
    "\n",
    "    for (i, J, p_on_J) in planned_attacks:\n",
    "        charges, final_state = battle(i, J, p_on_J, charges, final_state, final_state[i])\n",
    "        charges = check_structural_collapse(final_state, charges, loss_threshold=13, decay_factor=0.2)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    return final_state, charges\n",
    "\n",
    "def plot_state_frame(occ_state,I):\n",
    "\n",
    "    bkg_blank()\n",
    "\n",
    "    ind_state = np.where(occ_state == \"state\")[0]\n",
    "    ind_sunni = np.where(occ_state == \"sunni\")[0]\n",
    "    ind_kurds = np.where(occ_state == \"kurds\")[0]\n",
    "\n",
    "    x_state, y_state = [x_coord[ind_state],y_coord[ind_state]]\n",
    "    x_sunni, y_sunni = [x_coord[ind_sunni],y_coord[ind_sunni]]\n",
    "    x_kurds, y_kurds = [x_coord[ind_kurds],y_coord[ind_kurds]]\n",
    "\n",
    "    heatmap, xedges, yedges = np.histogram2d(x_state, y_state, bins=300)\n",
    "    plt.imshow( heatmap.T, origin='lower', cmap='ocean_r', \n",
    "        extent=[xedges[0], xedges[-1], yedges[0], yedges[-1]], alpha = 1\n",
    "    )\n",
    "\n",
    "    heatmap, xedges, yedges = np.histogram2d(x_sunni, y_sunni, bins=200)\n",
    "    plt.imshow( heatmap.T, origin='lower', cmap='viridis_r_alpha', \n",
    "        extent=[xedges[0], xedges[-1], yedges[0], yedges[-1]], alpha = 1\n",
    "    )\n",
    "\n",
    "    heatmap, xedges, yedges = np.histogram2d(x_kurds, y_kurds, bins=200)\n",
    "    plt.imshow( heatmap.T, origin='lower', cmap='magma_r_alpha', \n",
    "        extent=[xedges[0], xedges[-1], yedges[0], yedges[-1]], alpha = 1\n",
    "    )\n",
    "\n",
    "    plt.text(\n",
    "        0.03, 0.9, f\"{I+1}\",\n",
    "        transform=plt.gca().transAxes,\n",
    "        fontsize=14, color='white',\n",
    "        bbox=dict(facecolor='black', alpha=0.5, boxstyle='round,pad=0.3')\n",
    "    )\n",
    "\n",
    "    for city in cities:\n",
    "        plt.scatter(cities[city][0], cities[city][1], c='black', s=1, marker='+')\n",
    "\n",
    "    plt.savefig(f'images/frames/frame_{I+1}.png', bbox_inches = 'tight', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    return [len(x_state),len(x_sunni),len(x_kurds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd027a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "init_state = init_occ.copy()\n",
    "occ_nums = np.zeros((3,N))\n",
    "\n",
    "for iter in tqdm(range(N)):\n",
    "\n",
    "    out_state = iteration(init_state)\n",
    "    occ_nums[:,iter] = plot_state_frame(out_state,iter)\n",
    "    init_state = out_state.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "ca14071f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [01:45<00:00,  1.06s/it]\n"
     ]
    }
   ],
   "source": [
    "N = 100\n",
    "init_state = init_occ.copy()\n",
    "fiedler_init = compute_fiedler_values(init_state) \n",
    "charges = charges_calc(init_state, apply_fiedler_init=True, fiedler_init=fiedler_init)\n",
    "occ_nums = np.zeros((3,N))\n",
    "\n",
    "for iter in tqdm(range(N)):\n",
    "    new_recruit = charges_calc(init_state, apply_fiedler_init=False)\n",
    "    charges = 0.9999 * charges + 0.001 * new_recruit\n",
    "\n",
    "    out_state, charges = iteration(init_state, charges,iter)\n",
    "    occ_nums[:,iter] = plot_state_frame(out_state,iter)\n",
    "    init_state = out_state.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "2a01ed4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_files = sorted(glob.glob(\"images/frames/frame_*.png\"), key=lambda f: int(f.split('_')[-1].split('.')[0]))\n",
    "\n",
    "# Read and save as GIF\n",
    "frames = [imageio.imread(f) for f in frame_files]\n",
    "imageio.mimsave(\"images/animations/animation_test.gif\", frames, duration=0.4) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95da0a2b",
   "metadata": {},
   "source": [
    "## TO ADD\n",
    "\n",
    "Laplacian matrix with Fiedler value //\n",
    "Recruitment with Markov chain //\n",
    "Maybe Avalanche process to check collapse //"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
